{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1b00ac9-dc53-4713-a0ef-a9e609f5d16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_val_score, TimeSeriesSplit\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import ElasticNet, Lasso, LinearRegression, ridge_regression, LassoCV, RidgeCV\n",
    "from sklearn.linear_model import ElasticNetCV\n",
    "from sklearn.ensemble import AdaBoostRegressor, RandomForestRegressor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "659f04fd-e534-45bc-b9b1-911b0e5ee501",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5ca7168-5c35-440b-8dda-b4584c373988",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/sphenix/user/shuhangli/ppg12/FunWithxgboost/sig_takehome_daily.csv\")\n",
    "df['day'] = pd.to_datetime(df['day'])\n",
    "df = df.sort_values('day')\n",
    "df = df.set_index('day').sort_index()\n",
    "print(np.corrcoef(df['rv_lag1'], df['target_var_20d']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d7d8bf-5685-4878-a50a-2c22d328c9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f34e34-ff81-409d-8470-ba52cbdf9777",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = ['target_var_20d']\n",
    "fig, ax = plt.subplots(figsize = (9,4))\n",
    "ax.plot(df.index, df['target_var_20d'], label='vol')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "ax = df[target_col].plot(figsize=(9,4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477b847f-e25d-4d68-8b6f-e07a0c74917a",
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_cols = ['rv_lag1', 'rv_lag5', 'rv_lag22', 'realized_var', 'avg_spread_bps', 'avg_volume',\t'avg_mid']\n",
    "#feat_cols = ['rv_lag1', 'rv_lag5', 'rv_lag22']\n",
    "ax = df[feat_cols].plot(figsize = (9,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4ef897-c6bf-47e3-a057-bca7e46d3ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df[feat_cols+target_col].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e01502-d808-40d2-886b-94fc3bdc37ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c737a7-1b4e-4d0e-9f77-4df75b62ac38",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = 20\n",
    "rows = []\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "alphas = np.linspace(0.1,20,20)\n",
    "for i in range(train_len, len(df)-1):\n",
    "    train_df=df.iloc[i-train_len:i]\n",
    "    train_X = train_df[feat_cols].values\n",
    "    train_y = train_df[target_col[0]].values\n",
    "    test_df = df.iloc[i:i+1]\n",
    "    test_X = test_df[feat_cols].values\n",
    "    test_y = test_df[target_col[0]].values\n",
    "    #\n",
    "    pipe = Pipeline([('scaler', StandardScaler()), ('fitter', LinearRegression())])\n",
    "\n",
    "    r_cv = RidgeCV(cv = tscv, alphas=alphas)\n",
    "    pipe_ridge = Pipeline([('scaler', StandardScaler()), ('fitter', r_cv)])\n",
    "    \n",
    "    \n",
    "    pipe.fit(train_X, train_y)\n",
    "    pred_y = pipe.predict(test_X)\n",
    "\n",
    "    pipe_ridge.fit(train_X, train_y)\n",
    "    pred_ridge_y = pipe_ridge.predict(test_X)\n",
    "\n",
    "    used_alpha = pipe_ridge.named_steps['fitter'].alpha_\n",
    "\n",
    "    rows.append(\n",
    "        {\n",
    "            'day': test_df.index[0],\n",
    "            'target': test_y[0],\n",
    "            'pred_ols': pred_y[0],\n",
    "            'pred_ridge': pred_ridge_y[0],\n",
    "            'ridge_alpha': used_alpha,\n",
    "        }\n",
    "        \n",
    "    )\n",
    "\n",
    "result_df = pd.DataFrame(rows)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6450606-16e7-4a38-9dde-ab6c10352989",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_corr = result_df[['target', 'pred_ols', 'pred_ridge']].corr()\n",
    "result_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a302e9-afaa-451e-a672-8f2a52abfc2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ax = result_df[['target', 'pred_ols', 'pred_ridge']].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "793a6a0a-49ae-4079-a70b-b3d8d40156be",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result_df['ridge_alpha'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790fa076-6a88-4d6a-ab91-e6e353dcc31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2(y, yhat):\n",
    "    ybar = np.mean(y)\n",
    "    return 1.0 - np.sum((y - yhat)**2) / np.sum((y - ybar)**2)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "print(\"R2_ols\", r2(result_df['target'], result_df['pred_ols']))\n",
    "print(\"R2_ridge\", r2(result_df['target'], result_df['pred_ridge']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf50fde-5884-47dc-a01e-7baa7a4fa047",
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_df = pd.read_csv(\"/sphenix/user/shuhangli/ppg12/FunWithxgboost/VIXCLS.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0672cf01-b001-49ca-bcef-88f1e8dd0498",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(vol_df.head())\n",
    "vol_df['observation_date'] = pd.to_datetime(vol_df['observation_date'])\n",
    "vol_df = vol_df.sort_values(by='observation_date')\n",
    "vol_df.plot(x='observation_date', y='VIXCLS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf69f8b5-ef5e-486f-bad8-a61c9555b5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_df.isna().sum()\n",
    "print(vol_df.loc[vol_df['VIXCLS'].isna()])\n",
    "vol_df = vol_df.dropna()\n",
    "vol_df.iloc[-1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0167a397-aef7-4bde-99de-87093d7033dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = [1, 5, 22, 30]\n",
    "target_length = 20\n",
    "hs = [1,2,5]\n",
    "def build_features(df, vol_col_feat = 'VIXCLS'):\n",
    "    #build features\n",
    "    for k in ks:\n",
    "        df[f\"vol_lag_{k}\"] = df[vol_col].rolling(window = k).mean().shift(1)\n",
    "\n",
    "    #build target\n",
    "    df[f\"target_{target_length}d\"] = df[vol_col].rolling(window = target_length).mean().shift(-target_length)\n",
    "\n",
    "    for h in hs:\n",
    "        df[f\"target_h{h}d\"] = df[vol_col].shift(-h)\n",
    "        \n",
    "\n",
    "    return df.dropna()\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18983af1-0b2d-4bbc-8bff-02a9a8f4d6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed = build_features(vol_df.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99895baa-172c-4369-a45c-2ced2a580267",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53678d1b-1579-450b-8bd0-85acc5f477dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed.tail(100).plot(x='observation_date', y=['target_20d', 'vol_lag_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a542d50a-4f86-421f-8624-df96dbcb7649",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_prediction(df):\n",
    "    train_X = df[feat_cols].values\n",
    "    train_y = df[target_col[0]].values\n",
    "\n",
    "    pipe = Pipeline([('scaler', StandardScaler()), ('fitter', LinearRegression())])\n",
    "\n",
    "    r_cv = RidgeCV(cv = tscv, alphas=alphas)\n",
    "    pipe_ridge = Pipeline([('scaler', StandardScaler()), ('fitter', r_cv)])\n",
    "    \n",
    "    \n",
    "    pipe.fit(train_X, train_y)\n",
    "    pred_y = pipe.predict(test_X)\n",
    "\n",
    "    pipe_ridge.fit(train_X, train_y)\n",
    "    pred_ridge_y = pipe_ridge.predict(test_X)\n",
    "\n",
    "    return pred_y[0], pred_y_ridge[0]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1540eb2-49d2-4073-8c76-df615d3c90dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_processed.copy()\n",
    "feat_cols = [\"vol_lag_1\",\t\"vol_lag_5\",\t\"vol_lag_22\",\t\"vol_lag_30\"]\n",
    "target_col = ['target_h5d']\n",
    "train_len = 20\n",
    "rows = []\n",
    "tscv = TimeSeriesSplit(n_splits=5)\n",
    "alphas = np.linspace(0.1,20,20)\n",
    "for i in range(train_len, len(df)-1):\n",
    "    train_df=df.iloc[i-train_len:i]\n",
    "    train_X = train_df[feat_cols].values\n",
    "    train_y = train_df[target_col[0]].values\n",
    "    test_df = df.iloc[i:i+1]\n",
    "    test_X = test_df[feat_cols].values\n",
    "    test_y = test_df[target_col[0]].values\n",
    "    #\n",
    "    pipe = Pipeline([('scaler', StandardScaler()), ('fitter', LinearRegression())])\n",
    "\n",
    "    r_cv = RidgeCV(cv = tscv, alphas=alphas)\n",
    "    pipe_ridge = Pipeline([('scaler', StandardScaler()), ('fitter', r_cv)])\n",
    "    \n",
    "    \n",
    "    pipe.fit(train_X, train_y)\n",
    "    pred_y = pipe.predict(test_X)\n",
    "\n",
    "    pipe_ridge.fit(train_X, train_y)\n",
    "    pred_ridge_y = pipe_ridge.predict(test_X)\n",
    "\n",
    "    used_alpha = pipe_ridge.named_steps['fitter'].alpha_\n",
    "\n",
    "    rows.append(\n",
    "        {\n",
    "            'day': test_df.index[0],\n",
    "            'target': test_y[0],\n",
    "            'pred_ols': pred_y[0],\n",
    "            'pred_ridge': pred_ridge_y[0],\n",
    "            'ridge_alpha': used_alpha,\n",
    "        }\n",
    "        \n",
    "    )\n",
    "\n",
    "result_df = pd.DataFrame(rows)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f07f9016-4244-405e-9bc4-c10a08c3c781",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_corr = result_df[['target', 'pred_ols', 'pred_ridge']].corr()\n",
    "result_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d987ba0-0d3c-4569-a57f-42f0964beac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = result_df[['target', 'pred_ols', 'pred_ridge']].plot(figsize=(8,4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edd92235-683a-478b-b40d-dd93904cc8b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = result_df.iloc[-100:].plot(\n",
    "    x='day',\n",
    "    y=['target', 'pred_ols', 'pred_ridge'],\n",
    "    figsize=(8,4)\n",
    ")\n",
    "ax.set_xlabel('day')\n",
    "ax.set_ylabel('value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a93977c-9bd0-4469-933a-160976643fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2(y, yhat):\n",
    "    ybar = np.mean(y)\n",
    "    return 1.0 - np.sum((y - yhat)**2) / np.sum((y - ybar)**2)\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "print(\"R2_ols\", r2(result_df['target'], result_df['pred_ols']))\n",
    "print(\"R2_ridge\", r2(result_df['target'], result_df['pred_ridge']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5e4acd-344b-4d5b-9e09-4206cc46df2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69711c4f-2c88-40a2-87c6-523ffefd7d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(0)\n",
    "xs = rng.normal(size = 200)\n",
    "ys = xs*0.7 + rng.normal(scale = 0.5, size = 200)\n",
    "fig, ax = plt.subplots()\n",
    "ax.scatter(xs, ys, alpha = 0.7)\n",
    "ax.set(title='scatter', xlabel=\"x\", ylabel='y')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aafc3f4-57f4-44f9-b3fd-dad4dc9ff8a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.hist(result_df['target'],bins = 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9745395d-5d1d-4ca5-9188-2ee080d07bbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"somepath.csv\")\n",
    "\n",
    "df = df.rename(columns = str.lower).drop_duplicates()\n",
    "\n",
    "df.isna().mean().sort_values(ascending = False)\n",
    "df = df.dropna(subset=['target'])\n",
    "df['x'] = df['x'].fillna(df[\"x\"].median())\n",
    "\n",
    "\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['dow'] = df['date'].dt.dayofweel\n",
    "\n",
    "cat = ['sector', 'region']\n",
    "df[cat] = df[cat].astype('catagory')\n",
    "\n",
    "#groupby\n",
    "\n",
    "agg = df.groupby(\"user_id\").agg({\"amount\":[\"mean\", \"sum\", \"count\"]})\n",
    "\n",
    "agg.columns = [\"_\".join(c) for c in agg.columns]\n",
    "\n",
    "out = df.merge(agg, left_on = \"user_id\", right_index = True, how = \"left\")\n",
    "\n",
    "\n",
    "H = 20\n",
    "\n",
    "df[\"y\"] = np.log(df['price'].shift(-H)) - np.log(df['price'])\n",
    "\n",
    "df['ma_5'] = df['price'].rolling(5).mean().shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96d8419a-ba6e-42e1-b036-483b6fc2afb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "num = ['age', 'income', 'ma_5']\n",
    "cat = ['sector','region']\n",
    "\n",
    "pre = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", Pipeline([(\"imp\", SimpleImputer()),  (\"sc\", StandardScaler())    ]) , num      ),\n",
    "        (\"cat\", Pipeline( [(\"imp\", SimpleImputer(strategy=\"most_frequent\")), (\"oh\", OneHotEncoder(handle_unknown=\"ignore\"))   ]    )   ,cat)\n",
    "        \n",
    "    ],\n",
    "    remainder = 'drop'\n",
    ")\n",
    "\n",
    "model = Pipeline([(\"pre\", pre), (\"est\", Ridge(alpha = 1.0))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510898d1-d8e0-406b-bc56-7d7f0da87de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold, GroupKFold, TimeSeriesSplit\n",
    "\n",
    "#iid\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "#group\n",
    "\n",
    "cv = GroupKFold(n_splits=5).split(X,y, groups = df['user_id'])\n",
    "\n",
    "#ts split\n",
    "\n",
    "cs = TimeSeriesSplit(n_splits=5)\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score, roc_auc_score, average_precision_score, log_loss\n",
    "rmse = mean_squared_error(y_true, y_pred, squared = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57df1c2a-a451-4bf4-97cb-b652ebe51a69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "583c401c-147d-4d6b-813d-5c03f785a99c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "\n",
    "scorer = make_scorer(mean_squared_error, greater_is_better=False, squared = False)\n",
    "param_grid = {\"est__alpha\":[0.01, 0.1, 1, 10]}\n",
    "\n",
    "gs = GridSearchCV(model, param_grid = param_grid, scoring=scorer, cv = 5, n_jobs=1)\n",
    "\n",
    "gs.fit(X_train, y_train)\n",
    "best = gs.best_estimator_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ee8d5f-eff2-420d-9e83-aaa98e560bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "pipe = Pipeline([(\"pre\", pre), (\"est\", Ridge(alpha=1.0)) ] )\n",
    "pipe.fit(X_train, y_train)\n",
    "rmse = mean_squared_error(y_test,pipe.predict(X_test), squared = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e6df6bc-ded1-41b2-a92c-642335f70aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "clf = Pipeline(\n",
    "    [(\"pre\", pre), (\"est\", LogisticRegression(max_iter = 1000,  class_weight = \"balanced\"))   ]\n",
    ")\n",
    "clf.fit(X_train, y_train)\n",
    "p = clf.predict_proba(X_cal)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30674fb2-0c14-447e-8a62-958ce88c4d4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6597be-3c6c-4b7e-ba27-3b133a21ad6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "xgb = XGBRegressor(n_estimators = 1000, learning_rate = 0.05, subsample = 0.8, colsample_bytree = 0.8, tree_method = \"hist\")\n",
    "params = {\"max_depth\": [3,4,6,8], \"min_child_weight\": [1,3,5], \"reg_alpha\": [0,1e-2, 1e-1, 1], \"reg_lambda\": [0.1,1,5]}\n",
    "rs = RandomizedSearchCV(xgb,\n",
    "                        params,\n",
    "                        n_iter = 20,\n",
    "                        scoring=\"neg_root_mean_squared_error\",\n",
    "                        cv = 5, \n",
    "                        n_jobs = -1,\n",
    "                        random_state = 0\n",
    "                       )\n",
    "\n",
    "rs.fit(X_train, y_train, eval_set=[(X_val, y_val)], verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fafac5df-8f23-48dd-a2fa-899fedc9f4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "num_cols = ['age', 'income', 'ma_5']\n",
    "cat_cols = ['sector', 'region']\n",
    "target_col = 'y'\n",
    "\n",
    "X = df[num_cols + cat_cols]\n",
    "y = df[target_col] = \"y\"\n",
    "\n",
    "X_tr, X_te, y_re, y_te = train_test_split(X,y, test_size=0.2, random_state=0)\n",
    "\n",
    "pre = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', Pipeline\n",
    "         (\n",
    "            [\n",
    "                ('imp', SimpleImputer(strategy=\"median\")),\n",
    "                ('sc', StandardScaler())\n",
    "            ]\n",
    "        ), num_cols)\n",
    "        ('cat', Pipeline(\n",
    "            [\n",
    "                ('imp', SimpleImputer(strategy=\"most_frequent\")),\n",
    "                ('oh', OneHotEncoder(handle_unknown='ignore'))\n",
    "            ]\n",
    "        ), cat_cols)\n",
    "        \n",
    "        \n",
    "        \n",
    "    ],\n",
    "    remainder='drop'\n",
    "\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33f3b79-81f4-454b-88f1-74a8425689b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# helper functions\n",
    "def basic_info(df):\n",
    "    print(\"Shape: \",df.shape)\n",
    "    print(\"\\nDtypes:\\n\", df.dtypes)\n",
    "    print(\"\\n Head: \\n\", df.head(3))\n",
    "    print(\"\\n Tail: \\n\", df.tail(3))\n",
    "\n",
    "def missing_report(df):\n",
    "    miss = df.isna().sum().sort_values(ascending = False)\n",
    "    rate = df.isna().mean().sort_values(ascending = False)\n",
    "\n",
    "    out = pd.DataFrame({'missing': miss, 'missing_rate': rate})\n",
    "    return out[out['missing']>0]\n",
    "def numeric_summary(df, num_cols):\n",
    "    if not num_cols:\n",
    "        num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "    desc = df[num_cols].describe(percentiles = [.01, .05, .25, .5, .75,.95, .99]).T\n",
    "    desc['skew'] = df[num_cols].skew(numeric_only= True)\n",
    "    desc['kurt'] = df[num_cols].kurt(numeric_only= True)\n",
    "    return desc\n",
    "\n",
    "\n",
    "def categorical_summary(df, topn = 10):\n",
    "    cats = df.select_dypes(include=['object', 'category']).columns\n",
    "    res = {}\n",
    "    for c in cars:\n",
    "        vc = df[c].value_counts(dropna = False).head(topn)\n",
    "        res[c] = vc\n",
    "\n",
    "    return res\n",
    "\n",
    "\n",
    "\n",
    "def corr_top_pairs(df):\n",
    "    num = df.select_dtypes(include=[np.number])\n",
    "    c = num.corr()\n",
    "    return c\n",
    "\n",
    "\n",
    "def outlier_bounds(s, q=0.01):\n",
    "    lo, hi = s.quantile(q), s.quantile(1-q)\n",
    "    return lo, hi\n",
    "\n",
    "def ensure_datetime_index(df, data_col = \"DATE\"):\n",
    "    g = df.copy()\n",
    "\n",
    "    g[date_col] = pd.to_datetime(g[date_col])\n",
    "    g = g.sort_values(date_col)\n",
    "    g = g.set_index(data_col)\n",
    "\n",
    "#plotting helpers\n",
    "\n",
    "def plot_timeseries(df, ycols, title = None):\n",
    "    fig, ax = plt.subplots(figsize = (8,4))\n",
    "\n",
    "    for c in ycols:\n",
    "        ax.plot(df.index, df_ts[c], label = c)\n",
    "    ax.set(xlabel = \"date\", ylabel = \"value\", tital = title)\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "\n",
    "def plot_hist(df, cols, bins = 40):\n",
    "    fig, ax  = plt.subplots(figsize = (7,4))\n",
    "\n",
    "    for c in cols:\n",
    "        ax.hist(df[c].dropna().values, bins=bins, alpha = 0.5, label = c)\n",
    "    ax.set(xlabel = \"val\", ylabel = \"counts\")\n",
    "    ax.legend()\n",
    "    fig.tight_layout()\n",
    "\n",
    "def plot_scatter(df, x, y):\n",
    "    fig, ax = plt.subplots(figsize(5,4))\n",
    "    ax.scatter(df[x],df[y], alpha = 0.7)\n",
    "    ax.set(xlabel = x, ylabel = y)\n",
    "    fig.tight_layout()\n",
    "\n",
    "def plot_correlation_heatmap(df, topk = 12):\n",
    "    num = df.select_dtypes(include = [np.number])\n",
    "    c = num.corr()\n",
    "\n",
    "    cols = num.var().sort_values(ascending = False).head(topk).index\n",
    "\n",
    "    sub = c.loc[cols, cols]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize = (6,5))\n",
    "\n",
    "    im = ax.imshow(sub.values, aspect = \"auto\")\n",
    "    fig.colorbar(im, ax = ax)\n",
    "    fig.tight_layout()\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f394068b-c272-46d4-b099-93b9d1f9ac56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, cross_validate, RandomizedSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, Lasso, LarsCV, ElasticNet, ElasticNetCV\n",
    "from sklearn.ensemble import RandomForestRegressor, HistGradientBoostingClassifier\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.compose import TransformedTargetRegressor\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "##config\n",
    "\n",
    "@dataclass\n",
    "class SplitConfig:\n",
    "    test_size:float = 0.2\n",
    "    random_state: int = 42\n",
    "@dataclass\n",
    "class CVConfig:\n",
    "    n_splits: int = 5\n",
    "    random_state: int = 42\n",
    "    shuffle: bool = True\n",
    "\n",
    "\n",
    "##load and split\n",
    "\n",
    "\n",
    "def load_and_split(df, target, ignore = None, split_config = SplitConfig()):\n",
    "    ignore = ignore or []\n",
    "\n",
    "    X = df.drop(columns = [c for c in ignore+[target]])\n",
    "    y = df[target].astype(float)\n",
    "\n",
    "    num_cols = X.select_dtypes(include = [np.number]).columns.tolist()\n",
    "    cat_cols = X.select_dtypes(exclude = [np.number]).columns.tolist()\n",
    "\n",
    "    X_tr, X_te, y_tr, y_te = train_test_split(\n",
    "        X,y, test_size = split_config.test_size, random_state = split_config.random_state\n",
    "    )\n",
    "\n",
    "    return X_tr, X_te, y_tr, y_te, num_cols, cat_cols\n",
    "\n",
    "#generic preprocessor builder\n",
    "def make_preprocessor(num_cols, cat_cols):\n",
    "    num_pre = Pipeline([\n",
    "        (\"imp\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"sc\", StandardScaler()),\n",
    "        ])\n",
    "\n",
    "    cat_pre = Pipeline([\n",
    "        (\"imp\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"ohe\", OneHotEncoder()),\n",
    "        ])\n",
    "\n",
    "    return ColumnTransformer(\n",
    "        transformers=[\n",
    "            (\"num\", num_pre, num_cols),\n",
    "            (\"cat\", cat_pre, cat_cols),\n",
    "            \n",
    "        ],\n",
    "        remainder=\"drop\"\n",
    "    )\n",
    "\n",
    "def make_models(pre, seed):\n",
    "    return {\n",
    "        \"OLS\": Pipeline([('pre', pre), ('mdl', LinearRegression())]),\n",
    "        \"Ridge\": Pipeline([('pre', pre), ('mdl', Ridge(alpha=1.0, random_state=seed)  )]),\n",
    "        \"Lasso\": Pipeline([('pre', pre), ('mdl', Lasso(alpha = 0.01, random_state=seed)  )]),\n",
    "        \"ElasticNet\": Pipeline([('pre', pre), ('mdl', ElasticNet(alpha=0.01, l1_ratio=0.5, random_state = seed)  )]),\n",
    "        \"RF\": Pipeline([('pre', pre), ('mdl', RandomForestRegressor(n_estimators=300, random_state = seed)      )]),\n",
    "        \"XGB\": Pipeline([('pre', pre), ('mdl', XGBRegressor(random_state = seed, learning_rate = 0.05, n_estimators = 100, max_depth = 5))]),\n",
    "        \n",
    "    }\n",
    "\n",
    "def cv_compare(models, X, y, cv_cfg = CVConfig):\n",
    "    cv = KFold(n_splits = cv_cfg.n_splits, shuffle = cv_cfg.shuffle, random_state = cv_cfg.random_state)\n",
    "    scoring = {\"MAE\": \"neg_mean_absolute_error\", \"RMSE\": \"neg_root_mean_squared_error\", \"R2\": \"r2\"}\n",
    "    rows = []\n",
    "\n",
    "    for name, pipe in models.items():\n",
    "        print(f\"processing model {name}\")\n",
    "        res = cross_validate(pipe, X, y, cv = cv, scoring = scoring, return_train_score=False, n_jobs=-1)\n",
    "        rows.append({\n",
    "            \"model\": name,\n",
    "            \"MAE_CV\": -res[\"test_MAE\"].mean(),\n",
    "            \"RMSE_CV\": -res[\"test_RMSE\"].mean(),\n",
    "            \"R2_CV\": res[\"test_R2\"].mean(),\n",
    "            \"MAE_CV_std\": res[\"test_MAE\"].std(),\n",
    "            \"RMSE_CV_std\": res[\"test_RMSE\"].std(),\n",
    "            \"R2_CV_std\": res[\"test_R2\"].std(),\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows).sort_values(\"RMSE_CV\").reset_index(drop = True)\n",
    "\n",
    "\n",
    "def eval_models(models, X, y):\n",
    "    rows = []\n",
    "    for name, pipe in models.items():\n",
    "        y_hat = pipe.predict(X)\n",
    "        metric_dict = regression_metrics(y, y_hat)\n",
    "\n",
    "        metric_dict['model'] = name\n",
    "\n",
    "        rows.append(metric_dict)\n",
    "    return pd.DataFrame(rows)\n",
    "    \n",
    "def make_param_grid(model_name):\n",
    "    if model_name == \"Ridge\":\n",
    "        return {\"mdl__alpha\": np.logspace(-4,3,20).tolist()}\n",
    "\n",
    "    if model_name == \"ElasticNet\":\n",
    "        return {\"mdl__alpha\": np.logspace(-4,3,20).tolist(),\n",
    "                \"mdl__l1_ratio\": np.linspace(0.1,0.9,9).tolist()\n",
    "               }\n",
    "    if model_name == \"RF\":\n",
    "        return{\n",
    "            \"mdl__n_estimators\": [200, 300, 500],\n",
    "            \"mdl__max_depth\": [None, 10, 20],\n",
    "            \"mdl__min_samples_leaf\": [1,25]\n",
    "        }\n",
    "\n",
    "    if model_name == \"XGB\":\n",
    "        return {\n",
    "            \"mdl__n_estimators\": [50, 100, 400],\n",
    "            \"mdl__learning_rate\": [0.01, 0.03, 0.1],\n",
    "            \"mdl__max_depth\": [3,5,7],\n",
    "            \"mdl__min_child_weight\": [1,3,5],\n",
    "            \"mdl__subsample\": [0.7, 0.85, 1.0],\n",
    "            \"mdl__reg_alpha\": [0.0, 1e-3, 1e-2, 0.1],\n",
    "            \"mdl__reg_lambda\": [0.1, 1.0, 5.0],\n",
    "            \"mdl__gamma\": [0.0, 0.1, 1.0],\n",
    "                        \n",
    "        }\n",
    "    \n",
    "    return {}\n",
    "\n",
    "\n",
    "def randomized_tune(model_name, model, X, y, cv_cfg = CVConfig(), n_iter = 20, seed = 42):\n",
    "    grid = make_param_grid(model_name)\n",
    "    if not grid:\n",
    "        model.fit(X,y)\n",
    "        return model\n",
    "\n",
    "    cv = KFold(n_splits = cv_cfg.n_splits, shuffle = cv_cfg.shuffle, random_state = cv_cfg.random_state)\n",
    "    rs = RandomizedSearchCV(\n",
    "        estimator = model,\n",
    "        param_distributions=grid,\n",
    "        n_iter = n_iter,\n",
    "        scoring=\"neg_root_mean_squared_error\",\n",
    "        cv = cv,\n",
    "        random_state = seed,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    rs.fit(X,y)\n",
    "    print(f\"{model_name}: best params:\", rs.best_params_)\n",
    "    return rs.best_estimator_\n",
    "\n",
    "\n",
    "def regression_metrics(y_true, y_pred):\n",
    "    return{\n",
    "        \"MAE\": mean_absolute_error(y_true, y_pred),\n",
    "        \"RMSE\": mean_squared_error(y_true, y_pred, squared = False),\n",
    "        \"R2\": r2_score(y_true, y_pred),\n",
    "        \n",
    "    }\n",
    "\n",
    "def residual_plot(y_hat, y_true):\n",
    "    res = y_true - y_hat\n",
    "    fig, ax = plt.subplots(figsize(6,5))\n",
    "    ax.scatter(y_hat, res, alpha = 0.6)\n",
    "    ax.set(xlabel = \"predicted\", ylabel = \"residual\")\n",
    "    fig.tight_layout()\n",
    "    \n",
    "def permutation_importance_df(fitted_model, X, y, n_repeats = 10, seed = 42):\n",
    "    perm = permutation_importance(fitted_model, X,y, n_repeats = n_repeats, n_jobs=-1, random_state=seed)\n",
    "    feat_names = X.columns.to_list()\n",
    "    return pd.DataFrame({'feature': feat_names, \"importance\": perm.importances_mean}).sort_values(\"importance\", ascending = False)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f7b1c0-178a-42bd-8cae-ac58adcdb7e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/sphenix/user/shuhangli/ppg12/FunWithxgboost/winequality-data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44ed878c-0356-49cf-aabd-cb9ad035c9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_info(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cedd4b8e-56e5-49b6-8bc6-b0108986de9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_report(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dd823c6-047e-40e8-b87d-af8b653a392d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f69287-5c7e-45a5-a44e-e1e03453d82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa27a40-3b40-4922-9384-f3b6cdb06978",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034ca2b7-1d4b-4e37-b8aa-0f69bfe8a997",
   "metadata": {},
   "outputs": [],
   "source": [
    " X_tr, X_te, y_tr, y_te, num_cols, cat_cols = load_and_split(df, target='quality', ignore=['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a701554-1c91-4f58-827d-8affa9f051f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pre = make_preprocessor(num_cols,cat_cols)\n",
    "models = make_models(pre, seed = 42)\n",
    "cv_result = cv_compare(models, X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65544448-4a82-4531-828e-870b96c6ca8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cv_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d920b81a-2c99-433a-8b33-e203be7c2f56",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = {}\n",
    "for model_name, model in models.items():\n",
    "    best_models[model_name] = randomized_tune(model_name, model, X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b6cea4-7bbe-4313-b2b8-e1c82538545a",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_cv_result = cv_compare(best_models, X_tr, y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d3ec009-22b6-4d55-8244-b842fc746716",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best_model_cv_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f263675d-20a9-4afe-96fc-3928ab994f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_perm_result = permutation_importance_df(best_models['RF'],X_te, y_te) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e60402a6-574c-4e1d-a46f-990b8ca42836",
   "metadata": {
    "editable": true,
    "scrolled": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rf_perm_result.plot(x = 'feature', y = 'importance')\n",
    "rf_perm_result.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5e474a-23a3-4758-8002-1991ec0e34d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_hist(df, ['alcohol'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1e9f70-cdd8-41b9-90b2-5ebd99e5586a",
   "metadata": {},
   "outputs": [],
   "source": [
    " X_tr, X_te, y_tr, y_te, num_cols, cat_cols = load_and_split(df, target='quality', ignore=['id'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
